{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/course-python-primer/blob/main/lessons/06-web-scraping/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogv3aT3voFO7",
        "outputId": "3371936d-af9c-42b4-e094-6297046be65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter an extra URL (or leave blank to skip): \n",
            "Enclosing info:Enclosing info: Scraping local info...\n",
            "Global version: Scraper v1.0\n",
            " Scraping local info...\n",
            "Global version: Scraper v1.0\n",
            "Enclosing info: Scraping local info...\n",
            "Global version: Scraper v1.0\n",
            "Fetched https://www.python.org/downloads/release/python-31016 -> Python Release Python 3.10.16 | Python.org\n",
            "Fetched https://daily.dev/blog/python-and-javascript-choosing-your-first-language -> Python and JavaScript: Choosing Your First Language\n",
            "Fetched https://techcrunch.com/2025/02/15/openai-teases-a-simplified-gpt-5-model/ -> OpenAI teases a ‘simplified’ GPT-5 model | TechCrunch\n",
            "Title for https://www.python.org/downloads/release/python-31016: Python Release Python 3.10.16 | Python.org\n",
            "Title for https://daily.dev/blog/python-and-javascript-choosing-your-first-language: Python and JavaScript: Choosing Your First Language\n",
            "Title for https://techcrunch.com/2025/02/15/openai-teases-a-simplified-gpt-5-model/: OpenAI teases a ‘simplified’ GPT-5 model | TechCrunch\n",
            "Scraped 3 titles successfully, encountered 0 errors.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import threading\n",
        "\n",
        "# Global variable (for demonstration of resolution order)\n",
        "GLOBAL_VERSION = \"Scraper v1.0\"\n",
        "\n",
        "# Function to scrape a single URL\n",
        "def scrape_page(url, verbose=False):\n",
        "    \"\"\"\n",
        "    Scrapes the page title from a given URL.\n",
        "\n",
        "    :param url: URL to scrape.\n",
        "    :param verbose: If True, prints extra debug info.\n",
        "    :return: Title of the page or \"No Title Found\".\n",
        "    \"\"\"\n",
        "    # Enclosing scope variable\n",
        "    local_info = \"Scraping local info...\"\n",
        "\n",
        "    def show_info():\n",
        "        # Access 'local_info' from enclosing scope\n",
        "        print(\"Enclosing info:\", local_info)\n",
        "        # Access 'GLOBAL_VERSION' from global scope\n",
        "        print(\"Global version:\", GLOBAL_VERSION)\n",
        "\n",
        "    # Show how we can reference different scopes\n",
        "    show_info()\n",
        "\n",
        "    # Fetch page\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "    except requests.RequestException:\n",
        "        return \"Error Fetching Title\"\n",
        "\n",
        "    # Lambda function to extract title text\n",
        "    extract_title = lambda soup_obj: soup_obj.title.string if soup_obj.title else \"No Title Found\"\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    page_title = extract_title(soup)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Fetched {url} -> {page_title}\")\n",
        "\n",
        "    return page_title\n",
        "\n",
        "# Wrapper function to update the results dictionary\n",
        "def update_results(url, results, verbose):\n",
        "    results[url] = scrape_page(url, verbose=verbose)\n",
        "\n",
        "def run_scraper():\n",
        "    \"\"\"\n",
        "    Creates threads to scrape multiple URLs in parallel.\n",
        "    \"\"\"\n",
        "\n",
        "    # Our three sample URLs (feel free to replace them with any other public pages)\n",
        "    urls = [\n",
        "        \"https://www.python.org/downloads/release/python-31016\",\n",
        "        \"https://techcrunch.com/2025/02/15/openai-teases-a-simplified-gpt-5-model/\",\n",
        "        \"https://daily.dev/blog/python-and-javascript-choosing-your-first-language\"\n",
        "    ]\n",
        "\n",
        "    # Allow user to input an extra URL\n",
        "    extra_url = input(\"Enter an extra URL (or leave blank to skip): \")\n",
        "    if extra_url.strip():\n",
        "        urls.append(extra_url.strip())\n",
        "\n",
        "    results = {}\n",
        "    threads = []\n",
        "\n",
        "    # Create a thread for each URL\n",
        "    for link in urls:\n",
        "        t = threading.Thread(target=update_results, args=(link, results, True))\n",
        "        threads.append(t)\n",
        "\n",
        "    # Start all threads\n",
        "    for t in threads:\n",
        "        t.start()\n",
        "\n",
        "    # Wait for all threads to finish\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    # Print the final results\n",
        "    success_count = sum(1 for title in results.values() if title != \"Error Fetching Title\")\n",
        "    error_count = len(results) - success_count\n",
        "\n",
        "    for link, title in results.items():\n",
        "        print(f\"Title for {link}: {title}\")\n",
        "\n",
        "    print(f\"Scraped {success_count} titles successfully, encountered {error_count} errors.\")\n",
        "\n",
        "# Actual script entry point\n",
        "if __name__ == \"__main__\":\n",
        "    # Running the scraper\n",
        "    run_scraper()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uzvfyFCoFn8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
