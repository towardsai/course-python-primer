{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/course-python-primer/blob/main/lessons/09-news-analyzer/News_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YnDZgM0EBUKV",
        "outputId": "58fa9205-1773-4219-a4bb-83c30b54596f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/389.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m389.1/389.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio==5.18.0 openai==1.57.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "6quH-w_D9_uX",
        "outputId": "0319e7f8-2bef-4478-96e7-055f5efabc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://07ed1348a6942798ba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://07ed1348a6942798ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= \"Your_OpenAI_API_Key\"\n",
        "    # api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "# Function that communicates with an LLM to generate the summary, sentiment analysis, and tags\n",
        "def analyze_news_article(article_text):\n",
        "    \"\"\"\n",
        "    This function sends the article text to the LLM and expects a JSON output with:\n",
        "      - \"summary\"\n",
        "      - \"sentiment\"\n",
        "      - \"sentiment_confidence\"\n",
        "      - \"tags\"\n",
        "      - \"language\"\n",
        "    \"\"\"\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are helpful assistant for Article Analysis and Response in JSON Format\"\n",
        "    }\n",
        "    user_message = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\" You are an assistant that reads and analyzes a news article. You must return your answer in valid JSON format. Specifically, you will generate:\n",
        "1) \"summary\": A concise, 2-3 sentence overview of the key points in the article.\n",
        "2) \"sentiment\": One of the following strings: \"positive\", \"negative\", or \"neutral\".\n",
        "3) \"sentiment_confidence\": A numeric value between 0 and 1 indicating your confidence in the sentiment.\n",
        "4) \"tags\": A short list (3-5 items) of relevant keywords or topics from the article. These should be all lowercase, each word or short phrase separated by commas.\n",
        "5) \"language\": The language of the article, e.g., \"English\" or \"Spanish\".\n",
        "\n",
        "Other Important instructions you must follow:\n",
        "1. You must give only a JSON response – no additional prefix or suffix text.\n",
        "2. You are not allowed to include any explanations, apologies, or disclaimers.\n",
        "3. You must not output any JSON keys other than \"summary\", \"sentiment\", \"sentiment_confidence\", \"tags\", and \"language\".\n",
        "4. You must not include code fences (e.g., ```json ... ```).\n",
        "\n",
        "The response MUST be valid JSON and look like this:\n",
        "\n",
        "{{\n",
        "  \"summary\": \"...\",\n",
        "  \"sentiment\": \"...\",\n",
        "  \"sentiment_confidence\": 0.0,\n",
        "  \"tags\": [\"...\", \"...\"],\n",
        "  \"language\": \"...\"\n",
        "}}\n",
        "\n",
        "For example:\n",
        "\n",
        "{{\n",
        "  \"summary\": \"This article discusses the recent improvements in local education funding...\",\n",
        "  \"sentiment\": \"positive\",\n",
        "  \"sentiment_confidence\": 0.85,\n",
        "  \"tags\": [\"education\", \"funding\", \"local news\", \"policy\"],\n",
        "  \"language\": \"english\"\n",
        "}}\n",
        "\n",
        "Now, here is the text of the news article you should analyze:\n",
        "\n",
        "\\\"\\\"\\\" {article_text} \\\"\\\"\\\" \"\"\"\n",
        "    }\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-5-mini\",  # Update the Model you want\n",
        "            input=[system_message, user_message],\n",
        "            response_format={"type": "json_object"},\n",
        "        )\n",
        "        llm_response = response.choices[0].message.content\n",
        "        parsed = json.loads(llm_response)\n",
        "        summary = parsed.get(\"summary\", \"No summary found.\")\n",
        "        sentiment = parsed.get(\"sentiment\", \"No sentiment found.\")\n",
        "        confidence = parsed.get(\"sentiment_confidence\", 0)\n",
        "        tags = parsed.get(\"tags\", [])\n",
        "        language = parsed.get(\"language\", \"Unknown\")\n",
        "        return summary, f\"{sentiment} (confidence: {confidence})\", tags, language\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error during LLM analysis: {str(e)}\"\n",
        "        return error_msg, \"N/A\", [], \"Unknown\"\n",
        "\n",
        "# Function to update the Gradio UI with the results from the LLM\n",
        "def gradio_interface(article_text):\n",
        "    if len(article_text) > 20000: # 10000\n",
        "        return \"Error: Article is too long.\", \"N/A\", \"N/A\", \"N/A\"\n",
        "    summary, sentiment, tags, language = analyze_news_article(article_text)\n",
        "    with open(\"analysis_history.txt\", \"a\") as f:\n",
        "        f.write(f\"Summary: {summary}\\nSentiment: {sentiment}\\nTags: {tags}\\nLanguage: {language}\\n---\\n\")\n",
        "    return f\"Summary:\\n{summary}\", f\"Sentiment: {sentiment}\", f\"Tags: {tags}\", f\"Language: {language}\"\n",
        "\n",
        "# Build the Gradio app\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# News Analyzer (Summarize, Sentiment, and Tags)\")\n",
        "    article_input = gr.Textbox(\n",
        "        label=\"Paste your news article here\",\n",
        "        placeholder=\"Type or paste the text of a news article...\"\n",
        "    )\n",
        "    analyze_button = gr.Button(\"Analyze\")\n",
        "    summary_output = gr.Textbox(label=\"Summary\")\n",
        "    sentiment_output = gr.Textbox(label=\"Sentiment\")\n",
        "    tags_output = gr.Textbox(label=\"Tags\")\n",
        "    language_output = gr.Textbox(label=\"Language\")\n",
        "    analyze_button.click(\n",
        "        fn=gradio_interface,\n",
        "        inputs=article_input,\n",
        "        outputs=[summary_output, sentiment_output, tags_output, language_output]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWSu9tsRCfrF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
